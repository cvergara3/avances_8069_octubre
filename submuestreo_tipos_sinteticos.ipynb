{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c83cc3e3",
      "metadata": {
        "id": "c83cc3e3",
        "outputId": "07c5d3a8-d8b4-49b3-d27e-d907e6756186"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.load(\"/home/pc-2/Documents/CAVE_minciencias/final_model/resultados_STE/pct_10/run_pct10.npz\", allow_pickle=True)\n",
        "removed_idx = data[\"removed_idx\"]\n",
        "\n",
        "n_lines = 8\n",
        "n_cols = 64\n",
        "total = n_lines * n_cols\n",
        "\n",
        "mask_grid = np.zeros((n_lines, n_cols), dtype=int)\n",
        "\n",
        "for idx in removed_idx:\n",
        "    # INVERTIR LAS LÍNEAS:\n",
        "    line = n_lines - 1 - (idx // n_cols)   # antes: line = idx // n_cols\n",
        "    col  = idx % n_cols\n",
        "    mask_grid[line, col] = 1\n",
        "\n",
        "removed = len(removed_idx)\n",
        "keep = total - removed\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.imshow(\n",
        "    mask_grid,\n",
        "    cmap=\"gray_r\",\n",
        "    origin=\"lower\",         # ahora line=7 queda arriba, line=0 abajo\n",
        "    extent=[-0.5, n_cols - 0.5, -0.5, n_lines - 0.5],\n",
        "    aspect=\"auto\"\n",
        ")\n",
        "\n",
        "plt.title(f\"Plano de shots eliminados — 10% (negro = eliminado) | removed={removed}, keep={keep}\")\n",
        "plt.xlabel(\"Columna de shot (0..63)\")\n",
        "plt.ylabel(\"Línea (0..7)\")\n",
        "plt.xticks(np.arange(0, n_cols, 1))\n",
        "plt.yticks(np.arange(0, n_lines, 1))\n",
        "plt.grid(color=\"lightgray\", linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af3790d",
      "metadata": {
        "id": "5af3790d"
      },
      "source": [
        "## Submuestreo capa binaria entrenable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9567e73a",
      "metadata": {
        "id": "9567e73a",
        "outputId": "59425338-3daa-430a-fb7d-2131796b6208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Cargando archivos...\n",
            ">>> Cargados 512 shots.\n",
            ">>> Datos preparados (CRG, normalización, split).\n",
            ">>> Escenario 10%: preparando datos y modelo...\n",
            ">>> Escenario 10%: inferencia, métricas y guardado de figuras...\n",
            ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
            ">>> Listo.\n",
            ">>> Figuras y NPZ en: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_ste\n",
            ">>> Tabla de métricas CSV: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_ste/metrics_removed_shots_10_90.csv\n"
          ]
        }
      ],
      "source": [
        "import os, re, glob, numpy as np\n",
        "from obspy.io.segy.segy import _read_segy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pytorch_msssim import SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/final_model/shots_sinteticos_finales2D\"\n",
        "OUT_DIR  = os.path.join(\"/home/pc-2/Documents/CAVE_minciencias/final_model/\", \"salidas_crg_shotmask_ste\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "H, W = 512, 4096\n",
        "BATCH = 1\n",
        "EPOCHS = 3\n",
        "LR = 1e-4\n",
        "GLOBAL_SEED = 42\n",
        "LAMBDA_SPARSITY = 10\n",
        "#SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
        "SCENARIOS = [10]\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "\n",
        "def norm_trace_lastaxis(x):\n",
        "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
        "    return x / m\n",
        "\n",
        "def crop_to_mult8_2d(arr):\n",
        "    S, T = arr.shape[-2], arr.shape[-1]\n",
        "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
        "    if S8 != S or T8 != T:\n",
        "        arr = arr[..., :S8, :T8].copy()\n",
        "    return arr\n",
        "\n",
        "def check_divisible_by_8(h, w):\n",
        "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
        "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
        "\n",
        "def tag(fname):\n",
        "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def load_all(base_dir):\n",
        "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    arrs = []\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=False)\n",
        "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
        "        arrs.append(A)\n",
        "    return np.stack(arrs, 0), files\n",
        "\n",
        "class UNet2DFull(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def blk(cin, cout):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
        "                nn.Conv2d(cout, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
        "            )\n",
        "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
        "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
        "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
        "        self.bott = blk(256,512)\n",
        "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
        "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
        "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
        "        self.out = nn.Conv2d(64,1,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x); p1=self.p1(e1)\n",
        "        e2=self.e2(p1); p2=self.p2(e2)\n",
        "        e3=self.e3(p2); p3=self.p3(e3)\n",
        "        b=self.bott(p3)\n",
        "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
        "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
        "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
        "        return torch.tanh(self.out(d1))\n",
        "    @staticmethod\n",
        "    def crop(a,b):\n",
        "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
        "        dh,dw=(H-h)//2,(W-w)//2\n",
        "        return a[:,:,dh:dh+h, dw:dw+w]\n",
        "\n",
        "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "class BinaryShotMaskSTE(nn.Module):\n",
        "    \"\"\"\n",
        "    Aprende una prob(keep) por SHOT y elimina K = round(frac_remove * S) disparos\n",
        "    (las filas con menor prob(keep)), usando Straight-Through Estimator (STE).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_shots, init_keep_prob=0.9):\n",
        "        super().__init__()\n",
        "        self.n_shots = int(n_shots)\n",
        "        init_keep_prob = float(np.clip(init_keep_prob, 1e-3, 1-1e-3))\n",
        "        init_logit = np.log(init_keep_prob/(1-init_keep_prob))\n",
        "        self.logits = nn.Parameter(torch.full((self.n_shots,), float(init_logit)))\n",
        "        self.frac_remove = 0.10\n",
        "\n",
        "    def set_frac_remove(self, frac):\n",
        "        self.frac_remove = float(np.clip(frac, 0.0, 1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, 1, S, T)  -> enmascara la dimensión S (shots)\n",
        "        devuelve: x_masked, probs(sigmoid), hard(0/1 por shot)\n",
        "        \"\"\"\n",
        "        assert x.dim()==4 and x.shape[2]==self.n_shots, f\"Esperaba S={self.n_shots}, got {x.shape}\"\n",
        "        probs = torch.sigmoid(self.logits)\n",
        "        K = int(round(self.frac_remove * self.n_shots))\n",
        "        if K > 0:\n",
        "            idx_del = torch.topk(probs, K, largest=False).indices\n",
        "            hard = torch.ones_like(probs); hard[idx_del] = 0.0\n",
        "        else:\n",
        "            hard = torch.ones_like(probs)\n",
        "        ste_mask = hard + probs - probs.detach()\n",
        "        x_masked = x * ste_mask.view(1,1,self.n_shots,1)\n",
        "        return x_masked, probs, hard\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def hard_indices_removed(self):\n",
        "        probs = torch.sigmoid(self.logits)\n",
        "        K = int(round(self.frac_remove * self.n_shots))\n",
        "        if K <= 0: return np.array([], dtype=int)\n",
        "        idx_del = torch.topk(probs, K, largest=False).indices\n",
        "        return idx_del.cpu().numpy()\n",
        "\n",
        "print(\">>> Cargando archivos...\")\n",
        "gathers_shot, file_list = load_all(BASE_DIR)\n",
        "print(f\">>> Cargados {len(file_list)} shots.\")\n",
        "\n",
        "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
        "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
        "\n",
        "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
        "CRG_all = norm_trace_lastaxis(CRG_all)\n",
        "CRG_all = crop_to_mult8_2d(CRG_all)\n",
        "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
        "check_divisible_by_8(S8, T8)\n",
        "\n",
        "idx_rec = np.arange(CRG_all.shape[0])\n",
        "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
        "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
        "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
        "\n",
        "def train_unet_with_shotmask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR):\n",
        "    \"\"\"\n",
        "    Entrena U-Net con máscara binaria entrenable en dimensión SHOTS (STE).\n",
        "    Loss = (1-SSIM) + lambda_sparsity * (keep_mean - target_keep)^2\n",
        "    \"\"\"\n",
        "    S = CRG_tr.shape[1]\n",
        "    target_keep = 1.0 - (pct/100.0)\n",
        "\n",
        "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "\n",
        "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = UNet2DFull().to(device)\n",
        "    mask_layer = BinaryShotMaskSTE(n_shots=S, init_keep_prob=max(0.05, min(0.95, target_keep))).to(device)\n",
        "    mask_layer.set_frac_remove(pct/100.0)\n",
        "\n",
        "    opt = torch.optim.Adam([\n",
        "        {\"params\": model.parameters(), \"lr\": lr},\n",
        "        {\"params\": mask_layer.parameters(), \"lr\": lr}\n",
        "    ])\n",
        "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
        "\n",
        "    loss_hist = []\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        run = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            xb_masked, probs, hard = mask_layer(xb)       # enmascara SHOTS\n",
        "            yp = model(xb_masked)\n",
        "            loss_rec = 1 - crit(yp, yb)\n",
        "\n",
        "            keep_mean = torch.sigmoid(mask_layer.logits).mean()\n",
        "            loss_sp = (keep_mean - target_keep) ** 2\n",
        "\n",
        "            loss = loss_rec + LAMBDA_SPARSITY * loss_sp\n",
        "            loss.backward(); opt.step()\n",
        "            run += float(loss.item())\n",
        "        loss_hist.append(run / len(loader))\n",
        "\n",
        "    return model, mask_layer, loss_hist\n",
        "\n",
        "def eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2):\n",
        "    \"\"\"\n",
        "    Métricas SOLO sobre los shots eliminados (filas cero en la entrada por máscara).\n",
        "    Calcula MSE, PSNR, SSIM, SNR promediando sobre CRGs de test y shots eliminados.\n",
        "    \"\"\"\n",
        "    if len(removed_idx) == 0:\n",
        "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
        "\n",
        "    model.eval()\n",
        "    Htot, S, T = CRG_te.shape\n",
        "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "\n",
        "            xb_cpu = CRG_te[i0:i1].copy()\n",
        "            xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "\n",
        "            yp = model(xb).squeeze(1).cpu().numpy()\n",
        "            yt = CRG_te[i0:i1]\n",
        "\n",
        "            for b in range(yp.shape[0]):\n",
        "                ypn = yp[b, removed_idx]\n",
        "                ytn = yt[b, removed_idx]\n",
        "                mse = np.mean((ytn - ypn)**2)\n",
        "                amp = np.ptp(ytn) + 1e-8\n",
        "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
        "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
        "                snr = 10*np.log10((np.mean(ytn**2)+1e-12) / (mse+1e-12))\n",
        "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
        "\n",
        "            del xb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
        "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
        "\n",
        "def viz_shot_real_vs_pred_minibatch_masked(model, removed_idx, CRG_all, shot_idx,\n",
        "                                           save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    Htot, S, T = CRG_all.shape\n",
        "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
        "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_all[i0:i1].copy()\n",
        "            if len(removed_idx) > 0:\n",
        "                xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "            yb = model(xb).squeeze(1).cpu().numpy()\n",
        "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
        "            del xb, yb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    err = np.abs(pred_shot - real_shot)\n",
        "    fig1 = plt.figure(figsize=(18, 5))\n",
        "    ax1 = fig1.add_subplot(1,3,1)\n",
        "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
        "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax2 = fig1.add_subplot(1,3,2)\n",
        "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
        "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax3 = fig1.add_subplot(1,3,3)\n",
        "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
        "    ax3.set_title(\"Error absoluto\")\n",
        "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
        "    plt.close(fig1)\n",
        "\n",
        "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
        "    t = np.arange(pred_shot.shape[1])\n",
        "    fig2 = plt.figure(figsize=(16,4))\n",
        "    for k, r in enumerate(recs):\n",
        "        ax = fig2.add_subplot(1,3,k+1)\n",
        "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
        "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
        "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
        "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
        "        ax.grid(True); ax.legend()\n",
        "    fig2.tight_layout()\n",
        "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
        "    plt.close(fig2)\n",
        "\n",
        "def save_mask_bars(removed_idx, S, save_path, height=40, title=None):\n",
        "    mask = np.ones(S, dtype=np.float32)\n",
        "    mask[removed_idx] = 0.0\n",
        "    img = np.ones((height, S), dtype=np.float32)\n",
        "    img[:, mask == 0] = 0.0\n",
        "    fig = plt.figure(figsize=(14, 2.2))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
        "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice 0..S-1)\")\n",
        "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(save_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "def save_npz_per_pct(pct, probs, hard, logits, removed_idx, loss_hist, metrics_dict, out_dir):\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        probs=np.asarray(probs, dtype=np.float32),\n",
        "        hard=np.asarray(hard, dtype=np.float32),\n",
        "        logits=np.asarray(logits, dtype=np.float32),\n",
        "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "        MSE=(metrics_dict.get(\"MSE\") if metrics_dict else None),\n",
        "        PSNR=(metrics_dict.get(\"PSNR\") if metrics_dict else None),\n",
        "        SSIM=(metrics_dict.get(\"SSIM\") if metrics_dict else None),\n",
        "        SNR=(metrics_dict.get(\"SNR\") if metrics_dict else None),\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dict_losses = {}\n",
        "dict_metrics = {}\n",
        "dict_removed_counts = {}\n",
        "\n",
        "for pct in SCENARIOS:\n",
        "    print(f\">>> Escenario {pct}%: preparando datos y modelo...\")\n",
        "    model, mask_layer, loss_hist = train_unet_with_shotmask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR)\n",
        "    dict_losses[str(pct)] = loss_hist\n",
        "\n",
        "    print(f\">>> Escenario {pct}%: inferencia, métricas y guardado de figuras...\")\n",
        "    removed_idx = mask_layer.hard_indices_removed()\n",
        "    dict_removed_counts[str(pct)] = int(len(removed_idx))\n",
        "    S = CRG_all.shape[1]\n",
        "\n",
        "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
        "    os.makedirs(sc_dir, exist_ok=True)\n",
        "\n",
        "    save_mask_bars(removed_idx, S, os.path.join(sc_dir, \"mask_bars.png\"),\n",
        "                   title=f\"Máscara de shots — {pct}% eliminados\")\n",
        "\n",
        "    shots_sel = removed_idx[:min(3, len(removed_idx))] if len(removed_idx) > 0 else []\n",
        "    for s in shots_sel:\n",
        "        viz_shot_real_vs_pred_minibatch_masked(\n",
        "            model, removed_idx, CRG_all, s,\n",
        "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
        "        )\n",
        "\n",
        "    metrics = eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2)\n",
        "    dict_metrics[str(pct)] = metrics\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs_np = torch.sigmoid(mask_layer.logits).detach().cpu().numpy()\n",
        "        hard_np  = np.ones_like(probs_np, dtype=np.float32);\n",
        "        hard_np[removed_idx] = 0.0\n",
        "        logits_np = mask_layer.logits.detach().cpu().numpy()\n",
        "    save_npz_per_pct(pct, probs_np, hard_np, logits_np, removed_idx, loss_hist, metrics, sc_dir)\n",
        "\n",
        "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
        "    curve = dict_losses[k]\n",
        "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
        "plt.title(\"Curva de pérdida (1-SSIM + λ·sparsity) — escenarios 10–90% (mask SHOTS)\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_shotmask_10_90.png\"), dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "rows = []\n",
        "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
        "    m = dict_metrics[k] or {}\n",
        "    rows.append({\n",
        "        \"pct_removed\": int(k),\n",
        "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
        "        \"MSE\": m.get(\"MSE\", None),\n",
        "        \"PSNR\": m.get(\"PSNR\", None),\n",
        "        \"SSIM\": m.get(\"SSIM\", None),\n",
        "        \"SNR\": m.get(\"SNR\", None),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
        "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
        "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(\">>> Listo.\")\n",
        "print(\">>> Figuras y NPZ en:\", OUT_DIR)\n",
        "print(\">>> Tabla de métricas CSV:\", csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e1e00c",
      "metadata": {
        "id": "78e1e00c"
      },
      "source": [
        "## Submuestro Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ded0517",
      "metadata": {
        "id": "5ded0517",
        "outputId": "e89a03d2-4c5a-44b8-e8d7-cf9d18b33bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Cargando archivos...\n",
            ">>> Cargados 512 shots.\n",
            ">>> Datos preparados (CRG, normalización, split).\n",
            ">>> Escenario 10%: preparando datos y modelo...\n",
            ">>> Escenario 10%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 20%: preparando datos y modelo...\n",
            ">>> Escenario 20%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 30%: preparando datos y modelo...\n",
            ">>> Escenario 30%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 40%: preparando datos y modelo...\n",
            ">>> Escenario 40%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 50%: preparando datos y modelo...\n",
            ">>> Escenario 50%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 60%: preparando datos y modelo...\n",
            ">>> Escenario 60%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 70%: preparando datos y modelo...\n",
            ">>> Escenario 70%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 80%: preparando datos y modelo...\n",
            ">>> Escenario 80%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 90%: preparando datos y modelo...\n",
            ">>> Escenario 90%: inferencia, métricas y guardado de figuras...\n",
            ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
            ">>> Listo.\n",
            ">>> Figuras y NPZ en: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_random\n",
            ">>> Tabla de métricas CSV: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_random/metrics_removed_shots_10_90.csv\n"
          ]
        }
      ],
      "source": [
        "import os, re, glob, numpy as np\n",
        "from obspy.io.segy.segy import _read_segy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pytorch_msssim import SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/final_model/shots_sinteticos_finales2D\"\n",
        "OUT_DIR  = os.path.join(\"/home/pc-2/Documents/CAVE_minciencias/final_model/\", \"salidas_crg_shotmask_random\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "H, W = 512, 4096\n",
        "BATCH = 1\n",
        "EPOCHS = 40\n",
        "LR = 1e-4\n",
        "GLOBAL_SEED = 42\n",
        "SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "\n",
        "def norm_trace_lastaxis(x):\n",
        "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
        "    return x / m\n",
        "\n",
        "def crop_to_mult8_2d(arr):\n",
        "    S, T = arr.shape[-2], arr.shape[-1]\n",
        "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
        "    if S8 != S or T8 != T:\n",
        "        arr = arr[..., :S8, :T8].copy()\n",
        "    return arr\n",
        "\n",
        "def check_divisible_by_8(h, w):\n",
        "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
        "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
        "\n",
        "def tag(fname):\n",
        "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def load_all(base_dir):\n",
        "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    arrs = []\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=False)\n",
        "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
        "        arrs.append(A)\n",
        "    return np.stack(arrs, 0), files\n",
        "\n",
        "class UNet2DFull(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def blk(cin, cout):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
        "                nn.Conv2d(cout, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
        "            )\n",
        "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
        "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
        "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
        "        self.bott = blk(256,512)\n",
        "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
        "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
        "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
        "        self.out = nn.Conv2d(64,1,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x); p1=self.p1(e1)\n",
        "        e2=self.e2(p1); p2=self.p2(e2)\n",
        "        e3=self.e3(p2); p3=self.p3(e3)\n",
        "        b=self.bott(p3)\n",
        "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
        "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
        "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
        "        return torch.tanh(self.out(d1))\n",
        "    @staticmethod\n",
        "    def crop(a,b):\n",
        "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
        "        dh,dw=(H-h)//2,(W-w)//2\n",
        "        return a[:,:,dh:dh+h, dw:dw+w]\n",
        "\n",
        "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(\">>> Cargando archivos...\")\n",
        "gathers_shot, file_list = load_all(BASE_DIR)\n",
        "print(f\">>> Cargados {len(file_list)} shots.\")\n",
        "\n",
        "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
        "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
        "\n",
        "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
        "CRG_all = norm_trace_lastaxis(CRG_all)\n",
        "CRG_all = crop_to_mult8_2d(CRG_all)\n",
        "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
        "check_divisible_by_8(S8, T8)\n",
        "\n",
        "idx_rec = np.arange(CRG_all.shape[0])\n",
        "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
        "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
        "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
        "\n",
        "def train_unet_with_random_mask(CRG_tr, pct, device, epochs=BATCH, batch_size=BATCH, lr=LR):\n",
        "    \"\"\"\n",
        "    Entrena U-Net como autoencoder en CRG con una máscara ALEATORIA FIJA por escenario (SIN STE).\n",
        "    La entrada se enmascara poniendo a cero los shots eliminados; el objetivo es el CRG completo.\n",
        "    Loss = (1 - SSIM)\n",
        "    \"\"\"\n",
        "    S = CRG_tr.shape[1]\n",
        "    K = int(round((pct/100.0) * S))\n",
        "\n",
        "    rng = np.random.default_rng(GLOBAL_SEED + int(pct))\n",
        "    removed_idx = np.sort(rng.choice(S, size=K, replace=False)) if K > 0 else np.array([], dtype=int)\n",
        "\n",
        "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "\n",
        "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = UNet2DFull().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
        "\n",
        "    loss_hist = []\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        run = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            xb_masked = xb.clone()\n",
        "            if removed_idx.size > 0:\n",
        "                xb_masked[:,:,removed_idx,:] = 0.0\n",
        "            yp = model(xb_masked)\n",
        "            loss_rec = 1 - crit(yp, yb)\n",
        "            loss_rec.backward(); opt.step()\n",
        "            run += float(loss_rec.item())\n",
        "        loss_hist.append(run / len(loader))\n",
        "\n",
        "    return model, removed_idx, loss_hist\n",
        "\n",
        "def eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2):\n",
        "    \"\"\"\n",
        "    Métricas SOLO sobre los shots eliminados (filas cero en la entrada por máscara).\n",
        "    Calcula MSE, PSNR, SSIM, SNR promediando sobre CRGs de test y shots eliminados.\n",
        "    \"\"\"\n",
        "    if len(removed_idx) == 0:\n",
        "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
        "\n",
        "    model.eval()\n",
        "    Htot, S, T = CRG_te.shape\n",
        "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_te[i0:i1].copy()\n",
        "            xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "\n",
        "            yp = model(xb).squeeze(1).cpu().numpy()\n",
        "            yt = CRG_te[i0:i1]\n",
        "\n",
        "            for b in range(yp.shape[0]):\n",
        "                ypn = yp[b, removed_idx]\n",
        "                ytn = yt[b, removed_idx]\n",
        "                mse = np.mean((ytn - ypn)**2)\n",
        "                amp = np.ptp(ytn) + 1e-8\n",
        "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
        "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
        "                snr = 10*np.log10((np.mean(ytn**2)+1e-12) / (mse+1e-12))\n",
        "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
        "\n",
        "            del xb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
        "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
        "\n",
        "def viz_shot_real_vs_pred_minibatch_masked(model, removed_idx, CRG_all, shot_idx,\n",
        "                                           save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    Htot, S, T = CRG_all.shape\n",
        "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
        "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_all[i0:i1].copy()\n",
        "            if len(removed_idx) > 0:\n",
        "                xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "            yb = model(xb).squeeze(1).cpu().numpy()\n",
        "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
        "            del xb, yb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    err = np.abs(pred_shot - real_shot)\n",
        "    fig1 = plt.figure(figsize=(18, 5))\n",
        "    ax1 = fig1.add_subplot(1,3,1)\n",
        "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
        "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax2 = fig1.add_subplot(1,3,2)\n",
        "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
        "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax3 = fig1.add_subplot(1,3,3)\n",
        "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
        "    ax3.set_title(\"Error absoluto\")\n",
        "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
        "    plt.close(fig1)\n",
        "\n",
        "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
        "    t = np.arange(pred_shot.shape[1])\n",
        "    fig2 = plt.figure(figsize=(16,4))\n",
        "    for k, r in enumerate(recs):\n",
        "        ax = fig2.add_subplot(1,3,k+1)\n",
        "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
        "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
        "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
        "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
        "        ax.grid(True); ax.legend()\n",
        "    fig2.tight_layout()\n",
        "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
        "    plt.close(fig2)\n",
        "\n",
        "def save_mask_bars(removed_idx, S, save_path, height=40, title=None):\n",
        "    mask = np.ones(S, dtype=np.float32)\n",
        "    mask[removed_idx] = 0.0\n",
        "    img = np.ones((height, S), dtype=np.float32)\n",
        "    img[:, mask == 0] = 0.0\n",
        "    fig = plt.figure(figsize=(14, 2.2))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
        "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice 0..S-1)\")\n",
        "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(save_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "def save_npz_per_pct_random(pct, removed_idx, loss_hist, metrics_dict, out_dir):\n",
        "    \"\"\"\n",
        "    Guardado estilo compatible con tu flujo original.\n",
        "    Como no hay STE, los campos probs/logits se guardan como None y 'hard'\n",
        "    es el vector binario 1=keep/0=removed.\n",
        "    \"\"\"\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
        "    S = (removed_idx.max() + 1) if removed_idx.size > 0 else 0\n",
        "    hard = None\n",
        "    if metrics_dict is not None:\n",
        "        hard = None\n",
        "\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        probs=None,\n",
        "        hard=None,\n",
        "        logits=None,\n",
        "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "        MSE=(metrics_dict.get(\"MSE\") if metrics_dict else None),\n",
        "        PSNR=(metrics_dict.get(\"PSNR\") if metrics_dict else None),\n",
        "        SSIM=(metrics_dict.get(\"SSIM\") if metrics_dict else None),\n",
        "        SNR=(metrics_dict.get(\"SNR\") if metrics_dict else None),\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dict_losses = {}\n",
        "dict_metrics = {}\n",
        "dict_removed_counts = {}\n",
        "\n",
        "for pct in SCENARIOS:\n",
        "    print(f\">>> Escenario {pct}%: preparando datos y modelo...\")\n",
        "    model, removed_idx, loss_hist = train_unet_with_random_mask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR)\n",
        "    dict_losses[str(pct)] = loss_hist\n",
        "\n",
        "    print(f\">>> Escenario {pct}%: inferencia, métricas y guardado de figuras...\")\n",
        "    dict_removed_counts[str(pct)] = int(len(removed_idx))\n",
        "    S = CRG_all.shape[1]\n",
        "\n",
        "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
        "    os.makedirs(sc_dir, exist_ok=True)\n",
        "\n",
        "    save_mask_bars(removed_idx, S, os.path.join(sc_dir, \"mask_bars.png\"),\n",
        "                   title=f\"Máscara de shots — {pct}% eliminados\")\n",
        "\n",
        "    shots_sel = removed_idx[:min(3, len(removed_idx))] if len(removed_idx) > 0 else []\n",
        "    for s in shots_sel:\n",
        "        viz_shot_real_vs_pred_minibatch_masked(\n",
        "            model, removed_idx, CRG_all, s,\n",
        "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
        "        )\n",
        "\n",
        "    metrics = eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2)\n",
        "    dict_metrics[str(pct)] = metrics\n",
        "\n",
        "    save_npz_per_pct_random(pct, removed_idx, loss_hist, metrics, sc_dir)\n",
        "    hard_vec = np.ones(S, dtype=np.float32)\n",
        "    hard_vec[removed_idx] = 0.0\n",
        "    np.savez_compressed(os.path.join(sc_dir, f\"run_pct{pct:02d}.npz\"),\n",
        "                        probs=None,\n",
        "                        hard=hard_vec,\n",
        "                        logits=None,\n",
        "                        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "                        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "                        MSE=(metrics.get(\"MSE\") if metrics else None),\n",
        "                        PSNR=(metrics.get(\"PSNR\") if metrics else None),\n",
        "                        SSIM=(metrics.get(\"SSIM\") if metrics else None),\n",
        "                        SNR=(metrics.get(\"SNR\") if metrics else None))\n",
        "\n",
        "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
        "    curve = dict_losses[k]\n",
        "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
        "plt.title(\"Curva de pérdida (1-SSIM) — escenarios 10–90% (mask SHOTS ALEATORIA)\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_shotmask_10_90.png\"), dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "rows = []\n",
        "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
        "    m = dict_metrics[k] or {}\n",
        "    rows.append({\n",
        "        \"pct_removed\": int(k),\n",
        "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
        "        \"MSE\": m.get(\"MSE\", None),\n",
        "        \"PSNR\": m.get(\"PSNR\", None),\n",
        "        \"SSIM\": m.get(\"SSIM\", None),\n",
        "        \"SNR\": m.get(\"SNR\", None),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
        "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
        "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(\">>> Listo.\")\n",
        "print(\">>> Figuras y NPZ en:\", OUT_DIR)\n",
        "print(\">>> Tabla de métricas CSV:\", csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7cfba2f",
      "metadata": {
        "id": "e7cfba2f"
      },
      "source": [
        "## Submuetsreo Uniforme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3710edb",
      "metadata": {
        "id": "d3710edb",
        "outputId": "116845f2-32fe-40d1-aa82-03e4b007f3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Cargando archivos...\n",
            ">>> Cargados 512 shots.\n",
            ">>> Datos preparados (CRG, normalización, split).\n",
            ">>> Escenario 10%: preparando datos y modelo...\n",
            ">>> Escenario 10%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 20%: preparando datos y modelo...\n",
            ">>> Escenario 20%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 30%: preparando datos y modelo...\n",
            ">>> Escenario 30%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 40%: preparando datos y modelo...\n",
            ">>> Escenario 40%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 50%: preparando datos y modelo...\n",
            ">>> Escenario 50%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 60%: preparando datos y modelo...\n",
            ">>> Escenario 60%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 70%: preparando datos y modelo...\n",
            ">>> Escenario 70%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 80%: preparando datos y modelo...\n",
            ">>> Escenario 80%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 90%: preparando datos y modelo...\n",
            ">>> Escenario 90%: inferencia, métricas y guardado de figuras...\n",
            ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
            ">>> Listo.\n",
            ">>> Figuras y NPZ en: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_uniform\n",
            ">>> Tabla de métricas CSV: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_uniform/metrics_removed_shots_10_90.csv\n"
          ]
        }
      ],
      "source": [
        "import os, re, glob, numpy as np\n",
        "from obspy.io.segy.segy import _read_segy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pytorch_msssim import SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/final_model/shots_sinteticos_finales2D\"\n",
        "OUT_DIR  = os.path.join(\"/home/pc-2/Documents/CAVE_minciencias/final_model/\", \"salidas_crg_shotmask_uniform\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "H, W = 512, 4096\n",
        "BATCH = 1\n",
        "EPOCHS = 40\n",
        "LR = 1e-4\n",
        "GLOBAL_SEED = 42\n",
        "SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
        "#SCENARIOS = [10]\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "\n",
        "def norm_trace_lastaxis(x):\n",
        "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
        "    return x / m\n",
        "\n",
        "def crop_to_mult8_2d(arr):\n",
        "    S, T = arr.shape[-2], arr.shape[-1]\n",
        "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
        "    if S8 != S or T8 != T:\n",
        "        arr = arr[..., :S8, :T8].copy()\n",
        "    return arr\n",
        "\n",
        "def check_divisible_by_8(h, w):\n",
        "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
        "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
        "\n",
        "def tag(fname):\n",
        "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def load_all(base_dir):\n",
        "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    arrs = []\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=False)\n",
        "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
        "        arrs.append(A)\n",
        "    return np.stack(arrs, 0), files\n",
        "\n",
        "class UNet2DFull(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def blk(cin, cout):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
        "                nn.Conv2d(cout, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
        "            )\n",
        "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
        "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
        "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
        "        self.bott = blk(256,512)\n",
        "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
        "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
        "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
        "        self.out = nn.Conv2d(64,1,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x); p1=self.p1(e1)\n",
        "        e2=self.e2(p1); p2=self.p2(e2)\n",
        "        e3=self.e3(p2); p3=self.p3(e3)\n",
        "        b=self.bott(p3)\n",
        "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
        "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
        "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
        "        return torch.tanh(self.out(d1))\n",
        "    @staticmethod\n",
        "    def crop(a,b):\n",
        "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
        "        dh,dw=(H-h)//2,(W-w)//2\n",
        "        return a[:,:,dh:dh+h, dw:dw+w]\n",
        "\n",
        "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def uniform_keep_indices(S, keep_frac):\n",
        "    \"\"\"\n",
        "    Devuelve K índices casi equiespaciados en [0, S-1], con K = round(keep_frac * S).\n",
        "    Implementado por bins uniformes y elección del centro del bin (sin jitter).\n",
        "    \"\"\"\n",
        "    K = max(1, int(round(keep_frac * S)))\n",
        "    edges = np.linspace(0, S, K+1, endpoint=True).astype(int)\n",
        "    keep = []\n",
        "    for i in range(K):\n",
        "        a, b = edges[i], edges[i+1]\n",
        "        if b <= a:\n",
        "            continue\n",
        "        mid = (a + b - 1) / 2.0\n",
        "        keep.append(int(np.round(mid)))\n",
        "    keep = np.unique(np.clip(keep, 0, S-1))\n",
        "    return np.sort(keep)\n",
        "\n",
        "print(\">>> Cargando archivos...\")\n",
        "gathers_shot, file_list = load_all(BASE_DIR)\n",
        "print(f\">>> Cargados {len(file_list)} shots.\")\n",
        "\n",
        "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
        "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
        "\n",
        "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
        "CRG_all = norm_trace_lastaxis(CRG_all)\n",
        "CRG_all = crop_to_mult8_2d(CRG_all)\n",
        "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
        "check_divisible_by_8(S8, T8)\n",
        "\n",
        "idx_rec = np.arange(CRG_all.shape[0])\n",
        "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
        "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
        "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
        "\n",
        "def train_unet_with_uniform_mask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR):\n",
        "    \"\"\"\n",
        "    Entrena U-Net como autoencoder en CRG con una máscara UNIFORME FIJA por escenario (SIN STE).\n",
        "    La entrada se enmascara poniendo a cero los shots eliminados; el objetivo es el CRG completo.\n",
        "    Loss = (1 - SSIM)\n",
        "    \"\"\"\n",
        "    S = CRG_tr.shape[1]\n",
        "    keep_frac = 1.0 - (pct / 100.0)\n",
        "    keep = uniform_keep_indices(S, keep_frac)\n",
        "    removed_idx = np.array(sorted(set(range(S)) - set(keep)), dtype=int)\n",
        "\n",
        "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = UNet2DFull().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
        "\n",
        "    loss_hist = []\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        run = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            xb_masked = xb.clone()\n",
        "            if removed_idx.size > 0:\n",
        "                xb_masked[:,:,removed_idx,:] = 0.0\n",
        "            yp = model(xb_masked)\n",
        "            loss_rec = 1 - crit(yp, yb)\n",
        "            loss_rec.backward(); opt.step()\n",
        "            run += float(loss_rec.item())\n",
        "        loss_hist.append(run / len(loader))\n",
        "\n",
        "    return model, removed_idx, loss_hist\n",
        "\n",
        "def eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2):\n",
        "    if len(removed_idx) == 0:\n",
        "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
        "    model.eval()\n",
        "    Htot, S, T = CRG_te.shape\n",
        "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_te[i0:i1].copy()\n",
        "            xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "\n",
        "            yp = model(xb).squeeze(1).cpu().numpy()\n",
        "            yt = CRG_te[i0:i1]\n",
        "            for b in range(yp.shape[0]):\n",
        "                ypn = yp[b, removed_idx]\n",
        "                ytn = yt[b, removed_idx]\n",
        "                mse = np.mean((ytn - ypn)**2)\n",
        "                amp = np.ptp(ytn) + 1e-8\n",
        "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
        "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
        "                snr = 10*np.log10((np.mean(ytn**2)+1e-12) / (mse+1e-12))\n",
        "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
        "\n",
        "            del xb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
        "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
        "\n",
        "def viz_shot_real_vs_pred_minibatch_masked(model, removed_idx, CRG_all, shot_idx,\n",
        "                                           save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    Htot, S, T = CRG_all.shape\n",
        "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
        "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_all[i0:i1].copy()\n",
        "            if len(removed_idx) > 0:\n",
        "                xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "            yb = model(xb).squeeze(1).cpu().numpy()\n",
        "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
        "            del xb, yb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    err = np.abs(pred_shot - real_shot)\n",
        "    fig1 = plt.figure(figsize=(18, 5))\n",
        "    ax1 = fig1.add_subplot(1,3,1)\n",
        "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
        "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax2 = fig1.add_subplot(1,3,2)\n",
        "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
        "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax3 = fig1.add_subplot(1,3,3)\n",
        "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
        "    ax3.set_title(\"Error absoluto\")\n",
        "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
        "    plt.close(fig1)\n",
        "\n",
        "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
        "    t = np.arange(pred_shot.shape[1])\n",
        "    fig2 = plt.figure(figsize=(16,4))\n",
        "    for k, r in enumerate(recs):\n",
        "        ax = fig2.add_subplot(1,3,k+1)\n",
        "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
        "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
        "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
        "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
        "        ax.grid(True); ax.legend()\n",
        "    fig2.tight_layout()\n",
        "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
        "    plt.close(fig2)\n",
        "\n",
        "def save_mask_bars(removed_idx, S, save_path, height=40, title=None):\n",
        "    mask = np.ones(S, dtype=np.float32)\n",
        "    mask[removed_idx] = 0.0\n",
        "    img = np.ones((height, S), dtype=np.float32)\n",
        "    img[:, mask == 0] = 0.0\n",
        "    fig = plt.figure(figsize=(14, 2.2))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
        "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice 0..S-1)\")\n",
        "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(save_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "def save_npz_per_pct_uniform(pct, removed_idx, loss_hist, metrics_dict, out_dir, S_total):\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
        "    hard_vec = np.ones(S_total, dtype=np.float32)\n",
        "    hard_vec[removed_idx] = 0.0\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        probs=None,\n",
        "        hard=hard_vec,\n",
        "        logits=None,\n",
        "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "        MSE=(metrics_dict.get(\"MSE\") if metrics_dict else None),\n",
        "        PSNR=(metrics_dict.get(\"PSNR\") if metrics_dict else None),\n",
        "        SSIM=(metrics_dict.get(\"SSIM\") if metrics_dict else None),\n",
        "        SNR=(metrics_dict.get(\"SNR\") if metrics_dict else None),\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dict_losses = {}\n",
        "dict_metrics = {}\n",
        "dict_removed_counts = {}\n",
        "\n",
        "for pct in SCENARIOS:\n",
        "    print(f\">>> Escenario {pct}%: preparando datos y modelo...\")\n",
        "    model, removed_idx, loss_hist = train_unet_with_uniform_mask(\n",
        "        CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR\n",
        "    )\n",
        "    dict_losses[str(pct)] = loss_hist\n",
        "\n",
        "    print(f\">>> Escenario {pct}%: inferencia, métricas y guardado de figuras...\")\n",
        "    dict_removed_counts[str(pct)] = int(len(removed_idx))\n",
        "    S_total = CRG_all.shape[1]\n",
        "\n",
        "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
        "    os.makedirs(sc_dir, exist_ok=True)\n",
        "\n",
        "    save_mask_bars(removed_idx, S_total, os.path.join(sc_dir, \"mask_bars.png\"),\n",
        "                   title=f\"Máscara de shots — {pct}% eliminados (uniforme)\")\n",
        "\n",
        "    shots_sel = removed_idx[:min(3, len(removed_idx))] if len(removed_idx) > 0 else []\n",
        "    for s in shots_sel:\n",
        "        viz_shot_real_vs_pred_minibatch_masked(\n",
        "            model, removed_idx, CRG_all, s,\n",
        "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
        "        )\n",
        "\n",
        "    metrics = eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2)\n",
        "    dict_metrics[str(pct)] = metrics\n",
        "\n",
        "    save_npz_per_pct_uniform(pct, removed_idx, loss_hist, metrics, sc_dir, S_total)\n",
        "\n",
        "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
        "    curve = dict_losses[k]\n",
        "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
        "plt.title(\"Curva de pérdida (1-SSIM) — escenarios 10–90% (mask SHOTS UNIFORME)\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_shotmask_10_90.png\"), dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "rows = []\n",
        "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
        "    m = dict_metrics[k] or {}\n",
        "    rows.append({\n",
        "        \"pct_removed\": int(k),\n",
        "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
        "        \"MSE\": m.get(\"MSE\", None),\n",
        "        \"PSNR\": m.get(\"PSNR\", None),\n",
        "        \"SSIM\": m.get(\"SSIM\", None),\n",
        "        \"SNR\": m.get(\"SNR\", None),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
        "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
        "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(\">>> Listo.\")\n",
        "print(\">>> Figuras y NPZ en:\", OUT_DIR)\n",
        "print(\">>> Tabla de métricas CSV:\", csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa69b8b3",
      "metadata": {
        "id": "aa69b8b3"
      },
      "source": [
        "## Submuestreo Jittered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c2feb4",
      "metadata": {
        "id": "96c2feb4",
        "outputId": "78505e0d-141d-4d07-ab49-45b96d5ba797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Cargando archivos...\n",
            ">>> Cargados 512 shots.\n",
            ">>> Datos preparados (CRG, normalización, split).\n",
            ">>> Escenario 10%: preparando datos y modelo...\n",
            ">>> Escenario 10%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 20%: preparando datos y modelo...\n",
            ">>> Escenario 20%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 30%: preparando datos y modelo...\n",
            ">>> Escenario 30%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 40%: preparando datos y modelo...\n",
            ">>> Escenario 40%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 50%: preparando datos y modelo...\n",
            ">>> Escenario 50%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 60%: preparando datos y modelo...\n",
            ">>> Escenario 60%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 70%: preparando datos y modelo...\n",
            ">>> Escenario 70%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 80%: preparando datos y modelo...\n",
            ">>> Escenario 80%: inferencia, métricas y guardado de figuras...\n",
            ">>> Escenario 90%: preparando datos y modelo...\n",
            ">>> Escenario 90%: inferencia, métricas y guardado de figuras...\n",
            ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
            ">>> Listo.\n",
            ">>> Figuras y NPZ en: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_jittered\n",
            ">>> Tabla de métricas CSV: /home/pc-2/Documents/CAVE_minciencias/final_model/salidas_crg_shotmask_jittered/metrics_removed_shots_10_90.csv\n"
          ]
        }
      ],
      "source": [
        "import os, re, glob, numpy as np\n",
        "from obspy.io.segy.segy import _read_segy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pytorch_msssim import SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/final_model/shots_sinteticos_finales2D\"\n",
        "OUT_DIR  = os.path.join(\"/home/pc-2/Documents/CAVE_minciencias/final_model/\", \"salidas_crg_shotmask_jittered\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "H, W = 512, 4096\n",
        "BATCH = 1\n",
        "EPOCHS = 40\n",
        "LR = 1e-4\n",
        "GLOBAL_SEED = 42\n",
        "SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
        "ALPHA_JITTER = 0.3\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "\n",
        "def norm_trace_lastaxis(x):\n",
        "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
        "    return x / m\n",
        "\n",
        "def crop_to_mult8_2d(arr):\n",
        "    S, T = arr.shape[-2], arr.shape[-1]\n",
        "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
        "    if S8 != S or T8 != T:\n",
        "        arr = arr[..., :S8, :T8].copy()\n",
        "    return arr\n",
        "\n",
        "def check_divisible_by_8(h, w):\n",
        "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
        "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
        "\n",
        "def tag(fname):\n",
        "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def load_all(base_dir):\n",
        "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    arrs = []\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=False)\n",
        "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
        "        arrs.append(A)\n",
        "    return np.stack(arrs, 0), files\n",
        "\n",
        "class UNet2DFull(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def blk(cin, cout):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
        "                nn.Conv2d(cout, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
        "            )\n",
        "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
        "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
        "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
        "        self.bott = blk(256,512)\n",
        "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
        "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
        "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
        "        self.out = nn.Conv2d(64,1,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x); p1=self.p1(e1)\n",
        "        e2=self.e2(p1); p2=self.p2(e2)\n",
        "        e3=self.e3(p2); p3=self.p3(e3)\n",
        "        b=self.bott(p3)\n",
        "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
        "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
        "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
        "        return torch.tanh(self.out(d1))\n",
        "    @staticmethod\n",
        "    def crop(a,b):\n",
        "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
        "        dh,dw=(H-h)//2,(W-w)//2\n",
        "        return a[:,:,dh:dh+h, dw:dw+w]\n",
        "\n",
        "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def jittered_keep_indices(S, keep_frac, seed=0, alpha=0.3):\n",
        "    \"\"\"\n",
        "    S: total de shots\n",
        "    keep_frac: fracción a mantener (p.ej., 0.4 si eliminas 60%)\n",
        "    alpha: fracción del tamaño del bin para jitter (0..0.5 recomendado)\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    K = max(1, int(round(keep_frac * S)))\n",
        "    edges = np.linspace(0, S, K+1, endpoint=True).astype(int)  # K bins ~uniformes\n",
        "    keep = []\n",
        "    for i in range(K):\n",
        "        a, b = edges[i], edges[i+1]\n",
        "        if b <= a:\n",
        "            continue\n",
        "        L = b - a\n",
        "        c = (a + b - 1) / 2\n",
        "        J = int(np.floor(alpha * L))\n",
        "        lo = max(a, int(np.round(c)) - J)\n",
        "        hi = min(b-1, int(np.round(c)) + J)\n",
        "        keep.append(rng.integers(lo, hi+1))\n",
        "    keep = np.unique(np.clip(keep, 0, S-1))\n",
        "    return np.sort(keep)\n",
        "\n",
        "print(\">>> Cargando archivos...\")\n",
        "gathers_shot, file_list = load_all(BASE_DIR)\n",
        "print(f\">>> Cargados {len(file_list)} shots.\")\n",
        "\n",
        "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
        "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
        "\n",
        "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
        "CRG_all = norm_trace_lastaxis(CRG_all)\n",
        "CRG_all = crop_to_mult8_2d(CRG_all)\n",
        "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
        "check_divisible_by_8(S8, T8)\n",
        "\n",
        "idx_rec = np.arange(CRG_all.shape[0])\n",
        "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
        "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
        "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
        "\n",
        "def train_unet_with_jittered_mask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR, alpha=ALPHA_JITTER):\n",
        "    \"\"\"\n",
        "    Entrena U-Net como autoencoder en CRG con una máscara JITTERED FIJA por escenario (SIN STE).\n",
        "    La entrada se enmascara poniendo a cero los shots eliminados; el objetivo es el CRG completo.\n",
        "    Loss = (1 - SSIM)\n",
        "    \"\"\"\n",
        "    S = CRG_tr.shape[1]\n",
        "    keep_frac = 1.0 - (pct / 100.0)\n",
        "    keep = jittered_keep_indices(S, keep_frac=keep_frac, seed=GLOBAL_SEED + int(pct), alpha=alpha)\n",
        "    removed_idx = np.array(sorted(set(range(S)) - set(keep)), dtype=int)\n",
        "\n",
        "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = UNet2DFull().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
        "\n",
        "    loss_hist = []\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        run = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            xb_masked = xb.clone()\n",
        "            if removed_idx.size > 0:\n",
        "                xb_masked[:,:,removed_idx,:] = 0.0\n",
        "            yp = model(xb_masked)\n",
        "            loss_rec = 1 - crit(yp, yb)\n",
        "            loss_rec.backward(); opt.step()\n",
        "            run += float(loss_rec.item())\n",
        "        loss_hist.append(run / len(loader))\n",
        "\n",
        "    return model, removed_idx, loss_hist\n",
        "\n",
        "def eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2):\n",
        "    if len(removed_idx) == 0:\n",
        "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
        "\n",
        "    model.eval()\n",
        "    Htot, S, T = CRG_te.shape\n",
        "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_te[i0:i1].copy()\n",
        "            xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "\n",
        "            yp = model(xb).squeeze(1).cpu().numpy()\n",
        "            yt = CRG_te[i0:i1]\n",
        "\n",
        "            for b in range(yp.shape[0]):\n",
        "                ypn = yp[b, removed_idx]\n",
        "                ytn = yt[b, removed_idx]\n",
        "                mse = np.mean((ytn - ypn)**2)\n",
        "                amp = np.ptp(ytn) + 1e-8\n",
        "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
        "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
        "                snr = 10*np.log10((np.mean(ytn**2)+1e-12) / (mse+1e-12))\n",
        "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
        "\n",
        "            del xb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
        "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
        "\n",
        "def viz_shot_real_vs_pred_minibatch_masked(model, removed_idx, CRG_all, shot_idx,\n",
        "                                           save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    Htot, S, T = CRG_all.shape\n",
        "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
        "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0 + binf, Htot)\n",
        "            xb_cpu = CRG_all[i0:i1].copy()\n",
        "            if len(removed_idx) > 0:\n",
        "                xb_cpu[:, removed_idx, :] = 0.0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "            yb = model(xb).squeeze(1).cpu().numpy()\n",
        "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
        "            del xb, yb\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    err = np.abs(pred_shot - real_shot)\n",
        "    fig1 = plt.figure(figsize=(18, 5))\n",
        "    ax1 = fig1.add_subplot(1,3,1)\n",
        "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
        "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax2 = fig1.add_subplot(1,3,2)\n",
        "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
        "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
        "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
        "\n",
        "    ax3 = fig1.add_subplot(1,3,3)\n",
        "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
        "    ax3.set_title(\"Error absoluto\")\n",
        "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
        "    plt.close(fig1)\n",
        "\n",
        "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
        "    t = np.arange(pred_shot.shape[1])\n",
        "    fig2 = plt.figure(figsize=(16,4))\n",
        "    for k, r in enumerate(recs):\n",
        "        ax = fig2.add_subplot(1,3,k+1)\n",
        "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
        "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
        "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
        "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
        "        ax.grid(True); ax.legend()\n",
        "    fig2.tight_layout()\n",
        "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
        "    plt.close(fig2)\n",
        "\n",
        "def save_mask_bars(removed_idx, S, save_path, height=40, title=None):\n",
        "    mask = np.ones(S, dtype=np.float32)\n",
        "    mask[removed_idx] = 0.0\n",
        "    img = np.ones((height, S), dtype=np.float32)\n",
        "    img[:, mask == 0] = 0.0\n",
        "    fig = plt.figure(figsize=(14, 2.2))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
        "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice 0..S-1)\")\n",
        "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(save_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "def save_npz_per_pct_jittered(pct, removed_idx, loss_hist, metrics_dict, out_dir, S_total):\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
        "    hard_vec = np.ones(S_total, dtype=np.float32)\n",
        "    hard_vec[removed_idx] = 0.0\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        probs=None,\n",
        "        hard=hard_vec,\n",
        "        logits=None,\n",
        "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "        MSE=(metrics_dict.get(\"MSE\") if metrics_dict else None),\n",
        "        PSNR=(metrics_dict.get(\"PSNR\") if metrics_dict else None),\n",
        "        SSIM=(metrics_dict.get(\"SSIM\") if metrics_dict else None),\n",
        "        SNR=(metrics_dict.get(\"SNR\") if metrics_dict else None),\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dict_losses = {}\n",
        "dict_metrics = {}\n",
        "dict_removed_counts = {}\n",
        "\n",
        "for pct in SCENARIOS:\n",
        "    print(f\">>> Escenario {pct}%: preparando datos y modelo...\")\n",
        "    model, removed_idx, loss_hist = train_unet_with_jittered_mask(\n",
        "        CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR, alpha=ALPHA_JITTER\n",
        "    )\n",
        "    dict_losses[str(pct)] = loss_hist\n",
        "\n",
        "    print(f\">>> Escenario {pct}%: inferencia, métricas y guardado de figuras...\")\n",
        "    dict_removed_counts[str(pct)] = int(len(removed_idx))\n",
        "    S_total = CRG_all.shape[1]\n",
        "\n",
        "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
        "    os.makedirs(sc_dir, exist_ok=True)\n",
        "\n",
        "    save_mask_bars(removed_idx, S_total, os.path.join(sc_dir, \"mask_bars.png\"),\n",
        "                   title=f\"Máscara de shots — {pct}% eliminados (jittered)\")\n",
        "\n",
        "    shots_sel = removed_idx[:min(3, len(removed_idx))] if len(removed_idx) > 0 else []\n",
        "    for s in shots_sel:\n",
        "        viz_shot_real_vs_pred_minibatch_masked(\n",
        "            model, removed_idx, CRG_all, s,\n",
        "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
        "        )\n",
        "\n",
        "    metrics = eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2)\n",
        "    dict_metrics[str(pct)] = metrics\n",
        "\n",
        "    save_npz_per_pct_jittered(pct, removed_idx, loss_hist, metrics, sc_dir, S_total)\n",
        "\n",
        "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
        "    curve = dict_losses[k]\n",
        "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
        "plt.title(\"Curva de pérdida (1-SSIM) — escenarios 10–90% (mask SHOTS JITTERED)\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_shotmask_10_90.png\"), dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "rows = []\n",
        "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
        "    m = dict_metrics[k] or {}\n",
        "    rows.append({\n",
        "        \"pct_removed\": int(k),\n",
        "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
        "        \"MSE\": m.get(\"MSE\", None),\n",
        "        \"PSNR\": m.get(\"PSNR\", None),\n",
        "        \"SSIM\": m.get(\"SSIM\", None),\n",
        "        \"SNR\": m.get(\"SNR\", None),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
        "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
        "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(\">>> Listo.\")\n",
        "print(\">>> Figuras y NPZ en:\", OUT_DIR)\n",
        "print(\">>> Tabla de métricas CSV:\", csv_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "utah_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}